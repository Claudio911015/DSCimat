{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"Conditional VAE - Event probability estimator.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XWpBuKD60j0M","colab_type":"text"},"source":["# Conditional VAE - Event probability estimator\n","The goal of this tutorial is to implement a CVAE in order to model the probability of a vehicle of having an accident given the information we know about it.\n","In other words, we want to model $P(y|X)$, where $y$ is the number of accidents and $X$ is the information available about a vehicle. \n","\n","### **Steps:**\n","#### Step 1: Setup (librairies, data)\n","#### Step 2: Defining the model\n","#### Step 3: Defining the training procedure\n","#### Step 4: Train the model\n","#### Step 5: Testing the model on unseen data\n","\n"]},{"cell_type":"markdown","metadata":{"id":"5q084Sd-DFWR","colab_type":"text"},"source":["## **Step 1: Setup (librairies, data)**"]},{"cell_type":"markdown","metadata":{"id":"BrAtoAUGrAKu","colab_type":"text"},"source":["### Add dependencies"]},{"cell_type":"code","metadata":{"id":"zNRD5ehKq-qd","colab_type":"code","outputId":"6a772457-07e8-4ea3-e1bb-4170c28ab016","executionInfo":{"status":"ok","timestamp":1578361445284,"user_tz":300,"elapsed":7319,"user":{"displayName":"Marie-Ève Malette","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAwrTYZPeFd3b_Z0e7IC2Dx9pDRjjRt8MpBXw4CRw=s64","userId":"09624672134210041988"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["!pip install torch\n","!pip install googledrivedownloader"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.4)\n","Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (0.4)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U1W8egSgiT5a","colab_type":"text"},"source":["### Loading librairies"]},{"cell_type":"code","metadata":{"id":"Yb0S9ynPiT5b","colab_type":"code","colab":{}},"source":["import os\n","import time\n","import random\n","import math\n","import random\n","import numpy as np\n","import pandas as pd\n","import argparse\n","from itertools import chain\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import TensorDataset, DataLoader\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torch import device as device_\n","import sklearn.metrics as metrics\n","import matplotlib.pyplot as plt\n","from distutils.util import strtobool\n","from sklearn.preprocessing import StandardScaler\n","from random import sample\n","\n","from datetime import datetime\n","import sys\n","import os\n","import pickle\n","from scipy.stats import nbinom\n","from google.colab import files\n","import io\n","\n","from google_drive_downloader import GoogleDriveDownloader"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z6Rkwl1eiT5i","colab_type":"text"},"source":["### Uploading the data\n","The data has already been preprocessed and split into training, validation and test sets."]},{"cell_type":"code","metadata":{"id":"dBqd3A_SrSsg","colab_type":"code","outputId":"f3e6dfcc-e6f3-47c6-adfa-094ffd5a99d4","executionInfo":{"status":"ok","timestamp":1578375054952,"user_tz":300,"elapsed":7334,"user":{"displayName":"Marie-Ève Malette","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAwrTYZPeFd3b_Z0e7IC2Dx9pDRjjRt8MpBXw4CRw=s64","userId":"09624672134210041988"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["GoogleDriveDownloader.download_file_from_google_drive(file_id='1U986irw9-7FgVk35bQD3izhT4If0fWZx', dest_path='/data_train_.csv', unzip=False)\n","GoogleDriveDownloader.download_file_from_google_drive(file_id='1eLIITImFMu-BDMV2Iw7SrjdbVOh_Afnf', dest_path='/data_val_.csv', unzip=False)\n","GoogleDriveDownloader.download_file_from_google_drive(file_id='1JreaakeyJOSiRLqsOHGJUNC1alqXzo90', dest_path='/data_test_.csv', unzip=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading 1U986irw9-7FgVk35bQD3izhT4If0fWZx into /data_train_.csv... Done.\n","Downloading 1eLIITImFMu-BDMV2Iw7SrjdbVOh_Afnf into /data_val_.csv... Done.\n","Downloading 1JreaakeyJOSiRLqsOHGJUNC1alqXzo90 into /data_test_.csv... Done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1DjTzXauiT5m","colab_type":"code","outputId":"8c3d4bb6-8d16-484c-e6e6-0133bf02792f","executionInfo":{"status":"ok","timestamp":1578375061385,"user_tz":300,"elapsed":2118,"user":{"displayName":"Marie-Ève Malette","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAwrTYZPeFd3b_Z0e7IC2Dx9pDRjjRt8MpBXw4CRw=s64","userId":"09624672134210041988"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Using pandas, upload datasets to dataframes\n","data_train = pd.read_csv('/data_train_.csv')\n","data_val = pd.read_csv('/data_val_.csv')\n","data_test = pd.read_csv('/data_test_.csv')\n","\n","# Separate X from X\n","y_train = data_train['y'].values\n","y_val = data_val['y'].values\n","y_test = data_test['y'].values\n","\n","X_train = data_train.drop(['y'], axis=1).values\n","X_val = data_val.drop(['y'], axis=1).values\n","X_test = data_test.drop(['y'], axis=1).values\n","\n","# convert X,y pairs to dataloaders (this is specific to pytorch)\n","train_loader = DataLoader(TensorDataset(\n","                        torch.tensor(X_train, dtype=torch.float),\n","                        torch.tensor(y_train, dtype=torch.float)),\n","                    batch_size=32, shuffle=True\n","                    )\n","\n","val_loader = DataLoader(TensorDataset(\n","                torch.tensor(X_val, dtype=torch.float),\n","                torch.tensor(y_val, dtype=torch.float)),\n","            batch_size=X_val.shape[0], shuffle=True\n","            )\n","\n","test_loader = DataLoader(TensorDataset(\n","                torch.tensor(X_test, dtype=torch.float),\n","                torch.tensor(y_test, dtype=torch.float)),\n","            batch_size=X_test.shape[0], shuffle=True\n","            )\n","\n","print(data_train)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["             x1        x2        x3        x4        x5  ...  x79  x80  x81  x82  y\n","0     -0.283897 -0.237801 -0.049301 -0.103192 -0.097451  ...    0    0    0    0  1\n","1     -0.283897 -0.237801 -0.049301 -0.103192 -0.097451  ...    1    0    0    0  0\n","2     -0.283897 -0.237801 -0.049301 -0.103192 -0.097451  ...    0    0    1    0  1\n","3     -0.283897 -0.237801 -0.049301 -0.103192 -0.097451  ...    0    0    0    0  0\n","4     -0.283897 -0.237801 -0.049301 -0.103192 -0.097451  ...    0    0    0    1  1\n","...         ...       ...       ...       ...       ...  ...  ...  ...  ...  ... ..\n","35926 -0.283897 -0.237801 -0.049301 -0.103192 -0.097451  ...    1    0    0    0  0\n","35927 -0.283897 -0.237801 -0.049301 -0.103192 -0.097451  ...    0    0    0    0  1\n","35928 -0.283897 -0.237801 -0.049301 -0.103192 -0.097451  ...    0    0    0    0  0\n","35929 -0.283897 -0.237801 -0.049301 -0.103192 -0.097451  ...    1    0    0    0  0\n","35930 -0.283897 -0.237801 -0.049301 -0.103192 -0.097451  ...    0    0    0    0  0\n","\n","[35931 rows x 83 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MX7riGJM2J5n","colab_type":"text"},"source":["## **Step 2: Defining the Model**\n","Piece by piece, we will define the components of a Negative Binomial Conditional VAE\n","- A Classifier\n","- An Encoder\n","- A Prior Encoder\n","- A Recognition Encoder\n","- A Decoder\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Pr4jmZlSiT5o","colab_type":"text"},"source":["### The Classifier \n","The classifier's role is to provide an approximation of $y$. It maps $X$ to $y$ where in this cas $y$ was chosen to be a class. \n","\n","![alt text](https://drive.google.com/uc?id=1GBGLafjX_LsxT14p5obKhYrsqJ6Tf3E5)\n","\n"]},{"cell_type":"code","metadata":{"id":"RHCS7pn5iT5p","colab_type":"code","colab":{}},"source":["class Classifier(nn.Module):\n","    def __init__(self, input_dim, n_neurons, dropout, output_dim):\n","        super(Classifier, self).__init__()\n","\n","        self.n_neurons = n_neurons\n","        self.dropout = dropout\n","        self.input_dim = input_dim\n","\n","        layers = []\n","        n_layers = len(n_neurons)\n","\n","        # first layer\n","        layers.append(nn.Sequential(\n","            nn.Linear(input_dim, n_neurons[0]),\n","            nn.Tanh(),\n","            nn.Dropout(p=dropout),\n","            nn.BatchNorm1d(n_neurons[0]),\n","            )\n","        )\n","\n","        # hidden layers\n","        for i in range(1, n_layers):\n","            layers.append(nn.Sequential(\n","            nn.Linear(n_neurons[i-1], n_neurons[i]),\n","            nn.Tanh(),\n","            nn.Dropout(p=dropout),\n","            nn.BatchNorm1d(n_neurons[i]),\n","            )\n","        )\n","\n","\n","        self.lin = nn.Linear(n_neurons[-1], output_dim)\n","        self.soft = nn.Softmax(dim=1)\n","        self.fcl = nn.Sequential(*layers)\n","        \n","\n","    def forward(self, x):\n","        out = self.lin(self.fcl(x))\n","        return self.soft(out)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-q1RKfni5btt","colab_type":"text"},"source":["### The Encoder\n","Architecture for both the Prior Encoder and Recognition Encoder\n"]},{"cell_type":"code","metadata":{"id":"tq-PaUyoiT5r","colab_type":"code","colab":{}},"source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, latent_dim, n_neurons, dropout=0.):\n","        super(Encoder, self).__init__()\n","\n","        n1 = n_neurons[0]\n","        n2 = n_neurons[1]\n","\n","        self.encoder = nn.Sequential(\n","            nn.Linear(input_dim, n1),\n","            nn.Tanh(),\n","            nn.Dropout(p=dropout),\n","            nn.BatchNorm1d(n1),\n","            \n","            nn.Linear(n1, n2),\n","            nn.Tanh(),\n","            nn.Dropout(p=dropout),\n","            nn.BatchNorm1d(n2)\n","        )\n","\n","        self.read_mu = nn.Linear(n2, latent_dim)\n","        self.read_logvar = nn.Linear(n2, latent_dim)\n","\n","    def forward(self, y, X):\n","        inputs = torch.cat((y.unsqueeze(1).long(), X.long()), dim=1)\n","        out = self.encoder(inputs.float())\n","        mu = self.read_mu(out)\n","        logvar = self.read_logvar(out)\n"," \n","        return mu, logvar\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qv5udXn_5xbP","colab_type":"text"},"source":["### The Prior Encoder\n","Merging the Classifier and Encoder to model $p(z|X)$\n","\n","![alt text](https://drive.google.com/uc?id=1Z9EG-CDJK0vfPoYo9nZdeGC4PjfO1XaU)"]},{"cell_type":"code","metadata":{"id":"mkODRBu_iT5w","colab_type":"code","colab":{}},"source":["class PriorEncoder(nn.Module):\n","    def __init__(self, input_dim, latent_dim, n_neurons_mlp, n_neurons_e, dropout, output_dim):\n","        super(PriorEncoder, self).__init__()\n","\n","        self.clf = Classifier(input_dim-1, n_neurons_mlp, dropout, output_dim)\n","        self.encoder = Encoder(input_dim, latent_dim, n_neurons_e, dropout)\n","\n","    def parameters(self):\n","        return chain(self.clf.parameters(), self.encoder.parameters())\n","\n","    def forward(self, X):\n","        y_prob = self.clf(X)\n","        y_pred = torch.max(y_prob, 1)[1]\n","        mu, logvar = self.encoder(y_pred, X)\n","\n","        return mu, logvar\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hvZAVTAW59EC","colab_type":"text"},"source":["## The Recognition Encoder\n","To approximate $q(z|X,y)$, also serves as the support for training the Prior Encoder.\n","\n","![alt text](https://drive.google.com/uc?id=18Vz2LFMrE-pZf1-SyRCB9jiI-Obha9Zs)"]},{"cell_type":"code","metadata":{"id":"GLGIt9C7iT5y","colab_type":"code","colab":{}},"source":["class RecognitionEncoder(nn.Module):\n","    def __init__(self, input_dim, latent_dim, n_neurons_e, dropout):\n","        super(RecognitionEncoder, self).__init__()\n","\n","        self.encoder = Encoder(input_dim, latent_dim, n_neurons_e, dropout)\n","\n","    # def parameters(self):\n","    #     return chain(self.encoder.parameters())\n","\n","    def forward(self, y, X):\n","        mu, logvar = self.encoder(y, X)\n","        return mu, logvar\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kkGCK1Rc6J-4","colab_type":"text"},"source":["## The Decoder\n","Models $p(y|X,z)$\n","\n","![alt text](https://drive.google.com/uc?id=1bFIvOAm6xp3ovbFUqR1DLFSKCv4rK4rJ)"]},{"cell_type":"code","metadata":{"id":"FMbUsHU0iT5u","colab_type":"code","colab":{}},"source":["class Decoder(nn.Module):\n","    def __init__(self, input_dim, output_dim, n_neurons, dropout):\n","        super(Decoder, self).__init__()\n","\n","        n1 = n_neurons[0]\n","        n2 = n_neurons[1]\n","\n","        self.decoder = nn.Sequential(\n","            nn.Linear(input_dim, n1),\n","            nn.Tanh(),\n","            nn.Dropout(p=dropout),\n","            nn.BatchNorm1d(n1),\n","            \n","            nn.Linear(n1, n2),\n","            nn.Tanh(),\n","            nn.Dropout(p=dropout),\n","            nn.BatchNorm1d(n2),\n","\n","        )\n","\n","        self.fp = nn.Linear(n2, output_dim)\n","        self.fr = nn.Linear(n2, output_dim)\n","\n","    def forward(self, z, X):\n","        inputs = torch.cat((z, X), dim=1)\n","        out = self.decoder(inputs)\n","        r = torch.exp(self.fr(out))\n","        p = 1/(1 + torch.exp(-self.fp(out)))\n","        return r, p \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MYnja5hb6RkL","colab_type":"text"},"source":["# Putting all the pieces togetether\n","Now that we've defined all the different components of the Network, we can put it all together."]},{"cell_type":"code","metadata":{"id":"2PUx6KeXiT51","colab_type":"code","colab":{}},"source":["class NBCVAE(nn.Module):\n","\n","    def __init__(self, input_dim, latent_dim, n_neurons_e, n_neurons_d, n_neurons_mlp, dropout, output_dim):\n","        super(NBCVAE, self).__init__()\n","\n","        self.prior = PriorEncoder(input_dim+1, latent_dim,  n_neurons_mlp,  n_neurons_e, dropout, output_dim)\n","        self.recognition = RecognitionEncoder(input_dim+1, latent_dim, n_neurons_e, dropout)\n","        self.decoder = Decoder(input_dim+latent_dim, 1, n_neurons_d, dropout)\n","\n","        self.input_dim = input_dim\n","        self.latent_dim = latent_dim\n","        self.n_neurons_e = n_neurons_e\n","        self.n_neurons_d = n_neurons_d\n","        self.n_neurons_mlp = n_neurons_mlp\n","        self.dropout = dropout\n","        self.output_dim = output_dim\n","\n","\n","    def parameters(self):\n","        return chain(self.prior.parameters(), self.recognition.parameters(), self.decoder.parameters())\n","\n","\n","    def sample_z(self, mu, logvar):\n","        epsilon = torch.randn(mu.size())\n","        epsilon = Variable(epsilon, requires_grad=False).type(torch.FloatTensor)\n","        sigma = torch.exp(logvar / 2)\n","        return mu + sigma * epsilon\n","\n","\n","    def forward(self, y, X):\n","\n","        prior_mu, prior_logvar = self.prior(X)\n","        recogn_mu, recogn_logvar = self.recognition(y, X)\n","\n","        prior_z = self.sample_z(prior_mu, prior_logvar)\n","        recogn_z = self.sample_z(recogn_mu, recogn_logvar)\n","\n","        prior_r, prior_p  = self.decoder(prior_z, X)\n","        recogn_r, recogn_p  = self.decoder(recogn_z, X)\n","\n","        return recogn_r, recogn_p, prior_r, prior_p, recogn_mu, recogn_logvar, prior_mu, prior_logvar\n","\n","\n","    def save(self, model_path: str):\n","      \n","        checkpoint = {\n","            'model_state_dict': self.state_dict()\n","        }\n","        torch.save(checkpoint, model_path)\n","\n","    def load(self, model_path: str):\n","    \n","        checkpoint = torch.load(model_path)\n","        self.load_state_dict(checkpoint['model_state_dict'])\n","        return self "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2ewhwXWLiT56","colab_type":"text"},"source":["## **Step 3: Define the training procedure**"]},{"cell_type":"markdown","metadata":{"id":"yOdmPYakiT53","colab_type":"text"},"source":["### Define the loss function\n","Because we are using a negative binomial to model our $y$ variable, we need to define the reconstruction loss accordingly. \n"]},{"cell_type":"code","metadata":{"id":"-dVnJCV-iT54","colab_type":"code","colab":{}},"source":["class NBLLLoss:\n","    def __init__(self):\n","        pass\n","\n","    def logP(self, r, p, y):\n","        NB = torch.distributions.negative_binomial.NegativeBinomial(total_count=r.reshape(1, -1).squeeze(), \n","                                                                    probs=p.reshape(1, -1).squeeze())\n","        return NB.log_prob(y.reshape(1, -1).squeeze())\n","\n","    def NBLLoss(self, r, p, y):\n","        log_prob = self.logP(r, p, y)\n","        log_lik = torch.mean(log_prob)\n","            \n","        return -log_lik\n","\n","    def __call__(self, r, p, y):\n","        return self.NBLLoss(r, p, y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Be71St4iT57","colab_type":"code","colab":{}},"source":["class Trainer:\n","    def __init__(self, model, optimizer, criterion, n_epochs, path):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.criterion = criterion\n","        self.path = path\n","        self.n_epochs = n_epochs\n","\n","\n","    def train_iteration(self, train_loader):\n","        self.model.train()\n","        \n","        for X, y in train_loader:\n","\n","            self.optimizer.zero_grad()\n","            _,_, prior_r, prior_p, recogn_mu, recogn_logvar, prior_mu, prior_logvar = self.model(y, X)\n","\n","            loss_recon = self.criterion(prior_r, prior_p, y)\n","\n","            kl_div = torch.sum((torch.log(prior_logvar.exp()) - torch.log(recogn_logvar.exp())) + \n","                    ((recogn_logvar.exp()**2 + (recogn_mu - prior_mu)**2)/ (2*prior_logvar.exp()**2))) - 0.5\n","\n","            loss = loss_recon + kl_div\n","            loss.backward()\n","\n","            self.optimizer.step()\n","\n","\n","    def train(self, train_loader, val_loader, print_every=1, stopping_rule=1):\n","        best_epoch = 0\n","        best_loss = 100000\n","\n","        for epoch in range(self.n_epochs):\n","\n","            self.train_iteration(train_loader)\n","\n","            train_loss, train_loss_recon, train_kl_div  = self.evaluate(train_loader)\n","            valid_loss, valid_loss_recon, valid_kl_div   = self.evaluate(val_loader)\n","\n","            if valid_loss < best_loss:\n","                try:\n","                    os.remove('model_nbcvae.pt')\n","                except FileNotFoundError:\n","                    pass\n","                best_loss = valid_loss\n","                best_epoch = epoch\n","                self.model.save('model_nbcvae.pt')\n","                \n","            if (epoch + 1) % print_every == 0:\n","                message1 = f'| Epoch: {epoch+1:03}   | Train Loss: {train_loss:.3f} | Train Recon. Loss: {train_loss_recon:.3f} | Train KL Div: {train_kl_div:.3f}'\n","                message2 = f'|                Valid Loss: {valid_loss:.3f} | Valid Recon. Loss : {valid_loss_recon:.3f} | Valid KL Div: {valid_kl_div:.3f}'\n","                divider = '------------------------------------------------------------------------'\n","\n","                print(message1)\n","                print(message2)\n","                print(divider)\n","\n","            if epoch - best_epoch > stopping_rule:\n","                return epoch\n","\n","\n","    def evaluate(self, iterator):\n","        self.model.eval()\n","\n","        epoch_loss, epoch_loss_recon, epoch_kl_div = 0, 0, 0\n","        n_batch = 0 \n","\n","        with torch.no_grad():\n","            for X, y in iterator:\n","\n","                _,_, prior_r, prior_p, recogn_mu, recogn_logvar, prior_mu, prior_logvar = self.model(y, X)\n","\n","                loss_recon = self.criterion(prior_r, prior_p, y)\n","\n","                kl_div = torch.sum((torch.log(prior_logvar.exp()) - torch.log(recogn_logvar.exp())) +\n","                        ((recogn_logvar.exp()**2 + (recogn_mu - prior_mu)**2)/ (2*prior_logvar.exp()**2))) - 0.5\n","\n","                loss = loss_recon + kl_div/X.shape[0]\n","                epoch_loss += loss\n","                epoch_loss_recon += loss_recon\n","                epoch_kl_div += kl_div/X.shape[0]\n","                n_batch += 1\n","\n","        return 100*epoch_loss/n_batch, 100*epoch_loss_recon/n_batch, 100*epoch_kl_div/n_batch\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BE0c0IMWGd43","colab_type":"text"},"source":["## **Step 4: Train the model**"]},{"cell_type":"markdown","metadata":{"id":"2CILRYrYiT5-","colab_type":"text"},"source":["#### Training hyperparameters"]},{"cell_type":"code","metadata":{"id":"KC258ClSiT5_","colab_type":"code","colab":{}},"source":["latent_dim = 12\n","n_neurons_e = [100, 50]\n","n_neurons_d = [50, 100]\n","n_neurons_clf = [100,100]\n","dropout = 0.3\n","output_dim = 1\n","learning_rate = 0.000001\n","weight_decay = 0.01\n","n_epochs = 500\n","stopping_rule = 10\n","input_dim = X_train.shape[1]\n","betas=(0.93,0.99)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OEPB_1C2iT6B","colab_type":"code","colab":{}},"source":["# instantiate Negative \n","model = NBCVAE(\n","        input_dim=X_train.shape[1], \n","        latent_dim=latent_dim, \n","        n_neurons_e=n_neurons_e, \n","        n_neurons_d=n_neurons_d, \n","        n_neurons_mlp=n_neurons_clf,\n","        dropout=dropout,\n","        output_dim=len(np.unique(y_train))\n","        )\n","\n","\n","\n","# Define an Optimizer\n","optimizer = optim.Adam(\n","        model.parameters(),\n","        lr=learning_rate,\n","        betas=betas,\n","        weight_decay=weight_decay\n","    )\n","\n","\n","# Instantiate the reconstruction loss (during training we compute the KL divergence term)\n","criterion = NBLLLoss()\n","\n","# instantiate training procedure\n","trainer = Trainer(model=model,\n","                  optimizer=optimizer,\n","                  criterion=criterion,\n","                  n_epochs=n_epochs,\n","                  path=''\n","                 )\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Aiv8WEgYiT6D","colab_type":"code","outputId":"ac1f38fb-45b1-438b-cfef-2d6badfe1a3a","executionInfo":{"status":"error","timestamp":1578330078378,"user_tz":300,"elapsed":1107,"user":{"displayName":"Marie-Ève Malette","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAwrTYZPeFd3b_Z0e7IC2Dx9pDRjjRt8MpBXw4CRw=s64","userId":"09624672134210041988"}},"colab":{"base_uri":"https://localhost:8080/","height":164}},"source":["# train\n","trainer.train(train_loader, val_loader, stopping_rule=stopping_rule) "],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-84ddf6fb0501>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopping_rule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstopping_rule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"uFYiB6Y8iT6G","colab_type":"text"},"source":["\n","## **Step 5: Testing the model on unseen data**\n","We can create a class that will compute the probabilities for the test set and aggregate them.\n"]},{"cell_type":"code","metadata":{"id":"Rn2G4WthiT6G","colab_type":"code","colab":{}},"source":["class Probabilities:\n","    def __init__(self, model, NBLLLoss):\n","        self.model = model\n","        self.NBLLLoss = NBLLLoss\n","\n","\n","    def __call__(self, X, y):\n","        \n","        proba = pd.DataFrame(np.zeros((y.shape[0], 4)))\n","        proba.columns = ['P(y=0|X)', 'P(y=1|X)', 'P(y=2|X)', 'P(y=3|X)']\n","\n","        _, _, _ , _, _, _, prior_mu, prior_logvar = self.model(torch.Tensor(y), torch.Tensor(X))  \n","\n","        # sample 100 times\n","        p0 = np.zeros((y.shape[0], 100))\n","        p1 = np.zeros((y.shape[0], 100))\n","        p2 = np.zeros((y.shape[0], 100))\n","        p3 = np.zeros((y.shape[0], 100))\n","        \n","        for j in range(100):\n","            \n","            z = self.model.sample_z(prior_mu, prior_logvar)\n","            prior_r, prior_p  = self.model.decoder(z, torch.Tensor(X))\n","            NB = torch.distributions.negative_binomial.NegativeBinomial(total_count=prior_r.reshape(1, -1).squeeze().detach(), \n","                                                                        probs=prior_p.reshape(1, -1).squeeze().detach())\n","\n","            p0[:,j] = NB.log_prob(torch.ones(y.shape[0]) * 0).exp().detach().numpy()\n","            p1[:,j] = NB.log_prob(torch.ones(y.shape[0]) * 1).exp().detach().numpy()\n","            p2[:,j] = NB.log_prob(torch.ones(y.shape[0]) * 2).exp().detach().numpy()\n","            p3[:,j] = NB.log_prob(torch.ones(y.shape[0]) * 3).exp().detach().numpy()\n","\n","        proba['P(y='+str(0)+'|X)'] = p0.mean(axis=1)\n","        proba['P(y='+str(1)+'|X)'] = p1.mean(axis=1)\n","        proba['P(y='+str(2)+'|X)'] = p2.mean(axis=1)\n","        proba['P(y='+str(3)+'|X)'] = p3.mean(axis=1)\n","\n","        proba['nb_accidents'] = y\n","\n","        # summary\n","        summary = proba.groupby('nb_accidents').mean()\n","\n","        return summary, proba\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IXUpJM99eF_s","colab_type":"code","colab":{}},"source":["GoogleDriveDownloader.download_file_from_google_drive(file_id='1-jBD7wpWSfIgFEada_kdJFqzDHTyfncN', dest_path='/model_nbcvae.pt', unzip=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bm5KFOafiT6J","colab_type":"code","outputId":"803f86c7-a2c7-40b1-cebc-dd349c0d1850","executionInfo":{"status":"ok","timestamp":1578375298271,"user_tz":300,"elapsed":4652,"user":{"displayName":"Marie-Ève Malette","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAwrTYZPeFd3b_Z0e7IC2Dx9pDRjjRt8MpBXw4CRw=s64","userId":"09624672134210041988"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["# Load the model \n","model.load('/model_nbcvae.pt')\n","\n","# instantiate the Probabilities class\n","proba = Probabilities(model, NBLLLoss)\n","\n","# Get probabilities and summary\n","summary_test, proba_test = proba(X=X_test, y=y_test)\n","print(summary_test.iloc[:-1,:])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              P(y=0|X)  P(y=1|X)  P(y=2|X)  P(y=3|X)\n","nb_accidents                                        \n","0             0.880101  0.093410  0.019591  0.004899\n","1             0.853701  0.111196  0.025239  0.006753\n","2             0.845398  0.115078  0.027718  0.007877\n","3             0.848928  0.111399  0.027696  0.008039\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sukiOlULiT6L","colab_type":"code","outputId":"3eee7393-53f7-4594-f939-86ba4ce2dd87","executionInfo":{"status":"ok","timestamp":1578375560817,"user_tz":300,"elapsed":503,"user":{"displayName":"Marie-Ève Malette","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAwrTYZPeFd3b_Z0e7IC2Dx9pDRjjRt8MpBXw4CRw=s64","userId":"09624672134210041988"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# Let's isolate the probabilities of having 0 accidents\n","proba0 = proba_test['P(y=0|X)'].values\n","nb_accidents = proba_test['nb_accidents'].values\n","\n","# let's convert the number of accidents into a binary variable\n","had_accident = np.ones(proba_test.shape[0])\n","had_accident[nb_accidents == 0] = 0\n","\n","# Create a summary table with the probabilities of having 0 accidents and the binary accident variable\n","data_summary = pd.DataFrame({'proba': 1-proba0, 'had_accident': had_accident, 'nb_accidents': nb_accidents})\n","\n","# sort the probabilities from highest to lowest\n","data_summary = data_summary.sort_values(by='proba', ascending=False).reset_index(drop=True)\n","print(data_summary)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["         proba  had_accident  nb_accidents\n","0     0.571936           0.0             0\n","1     0.525143           0.0             0\n","2     0.519653           1.0             2\n","3     0.498163           0.0             0\n","4     0.492355           1.0             1\n","...        ...           ...           ...\n","7694  0.036111           0.0             0\n","7695  0.036070           0.0             0\n","7696  0.035873           0.0             0\n","7697  0.035570           0.0             0\n","7698  0.034338           0.0             0\n","\n","[7699 rows x 3 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"supI6SwAiT6Q","colab_type":"code","outputId":"7949f630-8980-48a1-afff-8278ba8a6cf3","executionInfo":{"status":"ok","timestamp":1578375568511,"user_tz":300,"elapsed":2328,"user":{"displayName":"Marie-Ève Malette","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAwrTYZPeFd3b_Z0e7IC2Dx9pDRjjRt8MpBXw4CRw=s64","userId":"09624672134210041988"}},"colab":{"base_uri":"https://localhost:8080/","height":265}},"source":["# plot the probabilities\n","LABEL_COLOR_MAP = {0 : 'b',\n","                   1 : 'r'\n","                   }\n","\n","\n","label_color = [LABEL_COLOR_MAP[l] for l in data_summary['had_accident'].values]\n","\n","plt.scatter(np.arange(proba_test.shape[0]), data_summary['proba'].values, c=label_color)\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdeZhcV30n/M+pqt73Vd0tqbVZkmVb\n8iYb2xjbgNnCvq9vMJCQBAwkeSGQZMJkYBgmhPBCZoABwpYM++7EBofFYGNsY3mVrX3f1Yt635fz\n/tFtIxuBhJFUKul8nqcf9b11q+6vquxvn3vuPeeGGKMkSZLkzJDJdwFJkiTJyZNCP0mS5AySQj9J\nkuQMkkI/SZLkDJJCP0mS5AySy9eOGxsb48KFC/O1+yRJkoJ0zz33dMUYm57o8/MW+gsXLrRmzZp8\n7T5JkqQghRB2/j7PP6bunRDCs0MIG0MIW0II7/kN27wihLAuhPBwCOHLv09RSZIkyYlx1JZ+CCGL\nj+MZ2IO7Qwg3xBjXHbbNUvw1nhxj7AkhNJ+ogpMkSZIn7lha+pdiS4xxW4xxHF/FCx+3zR/j4zHG\nHogxdhzfMpMkSZLj4VhCfy52H7a8Z3bd4ZZhWQjh9hDCnSGEZx/phUIIbw4hrAkhrOns7HxiFSdJ\nkiRP2PG6ZDOHpbgGr8ZnQgi1j98oxvjpGOPqGOPqpqYnfPI5SZIkeYKOJfT3Yv5hy/Nm1x1uD26I\nMU7EGLdjk5k/AkmSJMkp5FhC/24sDSEsCiEU41W44XHbfNdMK18IodFMd8+241hnkiRJchwcNfRj\njJO4HjdjPb4eY3w4hPC+EMILZje7Gd0hhHW4Be+KMXafqKKTJEmSJybkaz791atXxzQ4K0mS5HcT\nQrgnxrj6iT4/byNyn4ixMW68kQMHuPJKVq3Kd0VJkiSFpWBCf906rrmG0VEmJwmB5z2PL3+ZbDbf\n1SVJkhSGgphlM0Ze/GK6uhgYYGSE4eGZVv8XvpDv6pIkSQpHQYT+5s3s2TMT/ocbGuJTn8pPTUmS\nJIWoIEJ/fJzMb6h0bOzk1pIkSVLICiL0zzmHqqpfX19Wxuted/LrSZIkKVQFEfqZDF/5ChUVlJTM\nrKus5LzzuP76/NaWJElSSArm6p2rr2bLFr74xZn+/ac9jec/n1zBvIMkSZL8K6jIbGnh3e/OdxVJ\nkiSFqyC6d5IkSZLjI4V+kiTJGSSFfpIkyRkkhX6SJMkZJIV+kiTJGSSFfpIkyRkkhX6SJMkZpOBC\nf2qKwcFfn3wtSZIkObqCCf3JSd71LmpqqKtj4UK+9718V5UkSVJYCib03/Y2PvEJwtCA+ZPb7Ns1\n4TWv4bbb8l1ZkiRJ4SiI0O/v58ufH/Ox4Tfp0OxBq3Rq8vrhT3j/+/NdXZIkSeEoiNDfv5+PTr3N\nq31FmVGVhtTq8yHvsuj+7+S7vCRJkoJREKHf3jDkVZP/psLIY9ZXGvZXE/89T1UlSZIUnoII/bKR\nQ7JFRy61Pbv3JFeTJElSuAoi9LW2Kqoq/bXVMQRFT7k8DwUlSZIUpsII/VxO+PCHKS//1bpMRqio\n4L+n7p0kSZJjVRihD294A9/4BpdfTlsbL34xd93Fuefmu7IkSZKCcUyhH0J4dghhYwhhSwjhPUd4\n/LoQQmcI4f7Znz86/qWy74I/8PfP/IVXXrnXP1/1Tf3zzjkRu0mSJDltHfV2iSGELD6OZ2AP7g4h\n3BBjXPe4Tb8WYzxhtym/5x6e+lTGxxkb4z/+g//5P2fWt7aeqL0mSZKcXo6lpX8ptsQYt8UYx/FV\nvPDElvXr3vAGiga6vWXsn3zWG/3h8CeMdAz4678+2ZUkSZIUrmO5Mfpc7D5seQ+edITtXhpCuAqb\n8Bcxxt2P3yCE8Ga8Gdrb24+5yL4+rF9vsycrMarCiFf4uvdOvd8zvrdmtsQkSZLkaI7Xidx/x8IY\n4yr8EF880kYxxk/HGFfHGFc3NTUd84sXFfHJqT9Wq/fRAVqVhjTq9D/G/vI4lJ8kSXJmOJbQ34v5\nhy3Pm133qBhjd4xxbHbxX3Dx8SlvRnlu3GXxDhmPnU+5yJRnTd10PHeVJElyWjuW0L8bS0MIi0II\nxXgVbjh8gxDC4adSX4D1x69EZDIyuewRHyquKD6uu0qSJDmdHTX0Y4yTuB43mwnzr8cYHw4hvC+E\n8ILZzd4eQng4hPAA3o7rjmuVuZzwoheKRUWPXV9aKlz3+uO6qyRJktNZiHm6BdXq1avjmjVrjv0J\n3d0z12xu3870NCFw0UX84AePHambJElyGgsh3BNjXP1En38sV++cGhoaeOABbr2VzZtZtYpLLpkJ\n/yRJkuSYFE7oMxPwV18985MkSZL8zgpn7p1Z69fzne+wcWO+K0mSJCk8BdPSHx6emWPttttmrtuf\nmOCaa/j2tyn99VmXkyRJkiMomJb+u941050/MjJzz9yREW65hb/5m3xXliRJUjgKJvS/8AVGRx+7\nbnSUf/mXvJSTJElSkAoi9GOcadkfydDQya0lSZKkkBVE6IdARcWRHyspObm1JEmSFLKCCH1m5tA/\ny2af9UYPOdc3vcRF7jE6yuRkvqtLkiQpDAVz9c5VdWt9p+MKZUbkTDnbes92s/+n7Nuy2Wflu7wk\nSZKCUDAt/c/Wv1OFQTlTICuqMOyzJW8R5GcqiSRJkkJTMC399j2/MKTCv3md2z3Zchv9kc9qGdjF\nwADV1fkuMUmS5JRXMKHfVbfM6sFv69ZgSKUSIz7k3X6S/QOXlJXlu7wkSZKCUDDdO3/X/kX7tRpS\nCcaUGVTl9eVfnxmimyRJkhxVwYT+d7eca0KxZgf9gRtd6F5EWwZbdHbmu7okSZLCUDDdOyIf8k7X\n+7gxJXImbbPYcyZvVlLSevTnJ0mSJIXT0n+lr/kz/0eZUbX6VBqywnpfjy+TK5w/XUmSJHlVMKH/\n+p6PqvTYOReKTLrIvTru3ZOnqpIkSQpLwYR+c1HPEddPymkp7z/J1SRJkhSmggn97HOf6WErPMv3\nlRvSYr//4a9lc0HpqmX5Li9JkqQgFExv+Hhti8vdaVClKGNEuQ/4W1uml/vc5KTUsZ8kSXJ0BdPS\n/6fvLDKqVDys5GEVvjz9Svtv2ZDHypIkSQpHwYT+3RMXmFD8a+tLjdrQ3ZSHipIkSQpPwYT+OU+q\nYnaytcONKLf4KXNPfkFJkiQFqGBC/9KXzHekcmNRkbkp85MkSY5JwYT+zTdD+LX1uVxw++0nvZwk\nSZKCdEyhH0J4dghhYwhhSwjhPb9lu5eGEGIIYfXxK3HGvn1HXj8yMjOzcpIkSXJ0R73OMYSQxcfx\nDOzB3SGEG2KM6x63XRXegbtORKEzE2lGl7nT891gWLmveI1tlhgfPxF7TJIkOf0cy8Xtl2JLjHEb\nhBC+ihdi3eO2ez/+Ae86rhXOmtsWfcYfe7WvKDNiQs7f+KB3FH1CNnvdidhlkiTJaedYunfmYvdh\ny3tm1z0qhHAR5scYb/xtLxRCeHMIYU0IYU3n7zgf8jtW3eKlvuH/eq0r3eZaP/ZNL/PRiT/z9AsP\n/U6vlSRJcqb6vYexhhAy+AiuO9q2McZP49OwevXq3+nGtpdu+bJn+aafu9KYmTtlrbHaDZ7vm7ff\nTPurf+fakyRJzjTH0tLfi/mHLc+bXfeIKpyHn4YQduAy3HC8T+b+5MFGt7rK09zi617u217kuW50\ngxe4547UqZ8kSXIsjqWlfzeWhhAWmQn7V+E1jzwYY+xD4yPLIYSf4p0xxjXHs9CvdT/dR/yl63zx\n0SmWn+GHfuDZvvLAe1x8PHeWJElymjpq6McYJ0MI1+NmZPG5GOPDIYT3YU2M8YYTXSQUZye9yWdt\nsdQXvd6ASi/2Xc9xk7WHXoNLTkYZSZIkBe2Y+vRjjDfhpsete+9v2Paa37+sX/fihff77LY32Ohs\nTTox7S6X+LJXeFvFT/HSE7HbJEmS00rBzEe8bO6Qe1X6vDeZlDGmVLkhV7rd3r6NqZ2fJElyDApm\nGob7+xb7kPcYUuE867zYdzXocYtr3LWtOd/lJUmSFISCaemPHOxTZMx9LrTEFtOyio37ktf4yPhf\n+GC+C0ySJCkABRP6Rect9W93/aFzrFNs4tH1r/JVD1pl5qrRJEmS5LcpmO6d7JMudZXbbLfIn/mE\np/qJ9/pvhlX4M/8n3+UlSZIUhIJp6Z+/fMwtrvYi3zWmBFk/9RT/y/VuDs/Jd3lJkiQFoWBa+guv\nnOd1/tWYcjPDBSCnV53rKz+fz9KSJEkKRsG09LsPBd3mqNLvjT7rGrfYYplPeIu7B1bku7wkSZKC\nUDAt/Rhp0mmNi+WMe7d/9B+e67Ouc41bTE7mu8IkSZJTX8GEfk0NH/Bub/Mx7/C/bHC2H7nWmFJP\nd7Phod9p0s4kSZIzUsGEfnExDzrf9z3PPHsF5Ex7lh96ra8ZuGdjvktMkiQ55RVM6MPLfdNO7Z7r\nRjnjSg17o8+p02PtF+/Nd3lJkiSnvIIK/YV2WO1uh9T6sHf5oL+x3jJXuVX7oRT6SZIkR1MwV+/A\nl8If+sv4EWNK/bO3mZb1Cl9TbtDeyhXOyXeBSZIkp7iCCv0N5RfZOjRHo05fcJ1So77oD93sWTI7\n9nlGvgtMkiQ5xRVU986c4h7v8FFf8jr7tLnXRf7cx3zdK4wc7Mt3eUmSJKe8gmrp1zTkzO3Zp80+\nk3ImZQX8mU+6dPRupJujJ0mS/DYF1dJ/Se2PPNd/6FdrWKVxZcaU+bi3Kunvynd5SZIkp7yCCv29\n5ulTCxbb6ml+rEmHCSU+Ovonea4uSZLk1FdQob91xfNVGvRjT7XOCjf6A7vN88/eau1UunYnSZLk\naAoq9CuuWe2rXuWpfqrEhFLjSkx4q096k3/Jd3lJkiSnvIIK/YmhSc9ys4Ah5TZaZlCFjOhvfSDf\n5SVJkpzyCurqndaiTvAKX1ZhyAI7dGrUodVX0pU7SZIkR1VQLf2nv3qOP/f/adDlfhf5gP/qK/7Q\nmFLX+2i+y0uSJDnlFVToF1WVGlLhX73Bcpvc4AU+6U/tNM9G54lpduUkSZLfqqBCX4y2W+BfvMHN\nrvUHbvIqX9Op2UXutua7u/JdYZIkySntmEI/hPDsEMLGEMKWEMJ7jvD4n4YQ1oYQ7g8h/DyEcGKu\nn8xmXe4Or/E1vRoQEOw3z0f8v+757p4TstskSZLTxVFDP4SQxcfxHJyDVx8h1L8cY1wZY7wAH8JH\njnuls37kWo+EPVHW5OzvWV+5qeJE7TZJkuS0cCxX71yKLTHGbRBC+CpeiHWPbBBj7D9s+wqcsN71\ne2bvkfsh77LNEuuc7VJ322mBr3S99kTtNkmS5LRwLN07c7H7sOU9s+seI4Tw1hDCVjMt/bcf6YVC\nCG8OIawJIazp7Ox8IvWKct7jA97pnwwr9VpfUmbYv3uua33/Cb1mkiTJmeK4nciNMX48xrgE78Z/\n+Q3bfDrGuDrGuLqpqekJ7edpS3b4Z2/3f7zZT13jTT7vff6rq90mY/r3eAdJkiSnv2Pp3tmL+Yct\nz5td95t8FZ/8fYr6bf7k6Vs8a+v3/YnPuMwvTChSbMJurfZpO1G7TZIkOS0cS+jfjaUhhEVmwv5V\neM3hG4QQlsYYN88uPhebnSDzrj3HX3x6mWXWuc6/gp0WWGajn3iqb/7dhV72/otO1O6TJEkK2lG7\nd2KMk7geN2M9vh5jfDiE8L4QwgtmN7s+hPBwCOF+/CVef6IKvvzl81Ua9Kc+48P+wjaLTcnY4Gxb\nLfGN/77hRO06SZKk4B3T3Dsxxptw0+PWvfew399xnOv6rcoN+5qXO9d6wZRLrDGmxMPOFU2dzFKS\nJEkKSkFNuPaI+fYoNWKZ9da6wJe9Vr8aS2x0nn35Li9JkuSUVVjTMMxa9IJVltjiFs/wPS9VYcBy\nGwyo9kV/4sb/vT7fJSZJkpySCjL0P/SNpe5wubVW+qB3W2KHh6zUp857vc+b3pZG5iZJkhxJQYZ+\ncTGjSlzv4/7ef7HB2Sr1Kzfk866zXDqZmyRJciQFGfowoMp/erpm3Z7pB5bb4HJ3WWG9UiM23rL7\n6C+SJElyhinY0P+Hz80xoNpl7tCp2ct8y2prvMC/a9DrrU97MN8lJkmSnHIK8uodeO4b5vnnN96n\nxJhxxS7wgHq9oMUBP3JNfgtMkiQ5BRVs6EOTTmVGvMZXvNOH3OsS0zLm2+V/ereRgeuVVRX0W0yS\nJDmuCjoR55/XpO6hW7zW//UBf+flviXKKDPs/3qN/Zd+2l+sf0u+y0ySJDllFHTof3Dt8702dPmw\nd9pgue95gU7NSo2ba4e7Ngzmu8QkSZJTSkGHPtzrYvUO+YpXKTFpVJVGe6yzSo+GfJeXJElySin4\n0L8mc7vvTT9fv2ovdoNeNa7zRXu0+pFneuXVlb72swX5LjNJkuSUULCXbD7ijf98gWKTrvQLF7pH\nr2q3uVKPRsWG5G79z3yXmCRJcsoo+Jb+JW+93MD1ezzXf7jXhc6y2be8zKDq2Rk4bzfYM6Gyrijf\npSZJkuRdwbf0YVLGt7zENB5ygWvdrMUel7vDIc2eWf+zfJeYJElySjgtQn/fSKuzbPYfXmQSD7rA\nQjtc4pee70Y50z7/gR35LjNJkiTvTovQLykN6vT5I59SYtzVbjEuZ72zbbBck0O++19+ke8ykyRJ\n8u60CH247I9X+aXLVBq0U7t59lthnQvd60q/sNJGrwr/lu8ykyRJ8qrgT+Q+4tWffpaPfeanzrFZ\nj1rz7fQ5f2RKVpcmGZMW2GykZ1RZXWm+y02SJMmL06alD5/5ybl2mW+ZTf7V/yPKmG+vi93lKj9T\nYdj59ZvzXWaSJEnenFahv/KpTYIxUVaXRpX69CvzsPN0aUKJLjW+9L8P5rvUJEmSvDitQh9+EF+m\nX5Wnuc20oNi4pbbKmHSuta5xuw+/LbX2kyQ5M512oQ/V5811QKMBtWr0eaYbLbVFnypRRotuzw5f\ny3eZSZIkJ91pGfofXPtyVQa02qtet3tdrEOTDs3a7fQc3/d0d3h++FK+S02SJDmpTsvQh7d/6gJj\nSj3FLyy0w5ic1/u8b3i5e5zv+55jhxUuCz/Md6lJkiQnzWkb+q98cz0mTMn4mld6kRt82Lut8JBv\neZXdWgVTaoxqC+vzXW6SJMlJcUyhH0J4dghhYwhhSwjhPUd4/C9DCOtCCA+GEH4cQjgl5jLeFC8U\nUWFUwJt82n0u0W6bATUOaPFTV9tvifLQYXQ03xUnSZKcWEcN/RBCFh/Hc3AOXh1COOdxm92H1THG\nVfgmPnS8C32invrlt8iacKurfcLb1OrVqxbTmnQ4z4MudrcJpZrKOv3DX+zMd8lJkiQnzLG09C/F\nlhjjthjjOL6KFx6+QYzxlhjj8OzinZh3fMt84p786sXe+/z7XOk23RqdZZMBNRp1qXPIA1bLmHKR\ne13qF+7+6O0uCzfmu+wkSZIT4lhCfy52H7a8Z3bdb/ImfP9ID4QQ3hxCWBNCWNPZ2XnsVf6e/uyG\nl5h64xtd4eeqDSkxZr9Wd7vE+e6RMWWh7VbY7KAmw5qdE+5288fuP2k1JkmSnAzH9URuCOF1WI1/\nPNLjMcZPxxhXxxhXNzU1Hc9dH9XfffY8/3r7eXZqM6rcYtvNdcC0jHY7nGWr73ieXdqcY60R5V70\n5/PNDw+d1DqTJElOpGOZcG0v5h+2PG923WOEEK7F3+LqGOPY8Snv+Fp4RZtvPlRt5Xn9xpSYb49g\nWr863/ccQVBh2D1WW26DJbaKgieHPTLG3BZfePSdJEmSnMKOpaV/N5aGEBaFEIrxKtxw+AYhhAvx\nKbwgxthx/Ms8fhacW6lreI5hRfZrVqvPZX7pQed7jpvtsthF7jGhSIcmt3iaqEi3dheHO51dvT3f\nbyFJkuQJO2roxxgncT1uxnp8Pcb4cAjhfSGEF8xu9o+oxDdCCPeHEG74DS93Siguy9oSLxSN2aXZ\nmGK1Bv3SFS62Ro8GI8ptsNJSmz3sXEMqjMkqG9hrafil8fF8v4skSZLf3THNpx9jvAk3PW7dew/7\n/drjXNdJsTle4mVXb7H+1qWGlMiZtN0Sy210QJtzPGy7BVoc1KvKKjvc4VI9ap1b8oBpWetHz1Vc\nEvL9VpIkSY7JaXMTlSfqmz87C2d5SfiCScXG5JQY1a1JrV6VRtTqtcI6P/Q07fYpNWpa0KdSXWmH\ncqNuunWOS56Sbs6SJMmp7YwP/Ud8O17nLc/d4M6bijTbp8KQuQ4YUuNul2nQYantOtUrMWandtWG\nXOkOY7LeclWViBITbp24VjaXWv9Jkpx6Ttu5d56IT9x4to64RLdKC2y0S4spQb0eU4pMC6bkDKoR\n5VziLsXG9KqTMaXUmGFlFhc95PzwC5eEn+b7LSVJkjxGCv0jeCA+zR3xWQYV6VKjT6VJOfMcUK/P\noBqXuMuAGlFGlUGVhgyo0G6XaUXKDNplnivCzarCPleEH3vr87bk+60lSXKGS6H/W2yNl7jxxgor\n3atSjw71puXU6ZGTscxmfer0atSr3oRS97nQOR7So0GPBlstcYU73ekKd964y9ywQW3YpTVs9U//\n9VC+32KSJGeYEGPMy45Xr14d16xZk5d9PxHt4QHDqmVFXZpd6D6L7dCkyy9cocSYRbb6d89TpU+d\nPtX6tejwM1drscugGkyr0TvbJTQhiMqMWGqjhtpin+9+pZBJ5wOSJDmyEMI9McbVT/T56UTuMdoV\nzwcLwn2qFdlmgSq9dpkrioIpOy3RpMe4rPXOVWLCmDIr3euQGkWmVBkwpUilQUWile53v4uMqvLt\n3kv8KLtJlzoXWiNj2qfvuNq5l1Xl+d0nSXK6SN07v6Od8UI9cb6WOfQrU6XXtGhc1lw7TQsyppB1\nto3IImNEhTFletUbV2JSieXW26ndYlvc5ilypi21SbNOJaIObZ52eafKsFdd2KkpbHVeuN36e4aP\nUmWSJMmRpZb+E7TuQDvawVXhW4bVut2lpmREWQ322zU7Gem0jAG1lrjP3S4xz161euVMWWeVSgNa\ndIqCA+ZaaI/d5hlVokaPSS36VAumRRnPXL3dpCI1+u3UptmgHdPLhNQrlCTJUaTQPw5ujS8FPZ2T\nrmm+1aQy1foNqTIpGpO1yGZdGuVMmmn5l8sKyo0YVanMkCf7ufXOMSWrw1yNOm12oSqdMoJGPSr1\nKzXiIavkTGrUa56dqjOVFtlqm8WGNFi2YMTGHXX5/WCSJDnlpO6d46iuKeeB+DQPx8v97deebMK0\nUn32ajGozLBiS21UrF+T/YJxw8rljJmWkRPV6dGr0Vm2qTJgpfu06FSvV5EJE0rttNgV7kBOkUnb\nLNVqv7Uut9Bez3CjzTtpD2stC3dpDFvVhL0Wl+/K90eUJEmepdA/QZ73ikrr45U64grDcY4Xv4Ai\nw3qU61dunyYHNVlqvTb7FBnRoV6/alOypmVEOY26nG+tQTWzrf1DgiK3e7oL3KdLm7Nss9lFzrLW\nYtv9wlXadGnQp1+TcWXOsU5mpNOCsNa8sNaScL/l4S4Xhx+5NNxi7+Z0niBJzgQp9E+S//29s+2O\nK+2PK3TGpd7/j/XWW6zBfl2qdKlziysNK7LMetu1i6ZttMw6ZysyIoMhleY4oM4h5EzL2GKZcv2m\nFbvdk9XoN8cBG6xUbNL5HjSowpBq40o06tVut0pDDmnSocGKZT3ODr+0ItxhXljn3HCXK8IPfPlj\n6eggSU4nKfTz5A/fOdeeeL7vx9fYGVcZiHP90dU77NVonUUW2mSr+fZpdlCjPrWYVGrYHnMNqpQx\nbVpWjzoNumRNO6RFmTFZzLHPgGqbrDCpRKMePRpNKBXlDGoQBD2a1MxeSjqoxqQilYZNKPJ3f96h\nIhwUwqi2sF5V2K027HHtJaf0bROSJPkN0uCsU9jn37/Z29+bNaheuQFTctocFGQUmdCiw/0utMLD\n7nepOp32m2+B7Wr0m1Bkse3ucYGAHnWucqt+lTo02Wuu6tmBZDmThlSo1KvKkGlBh2YHzFFhyJSc\nKRlLbDWsVM6Eej1KjdhlvilFtptvWrWXvyTn69/K5vvjS5LT0u87OCu19E9hb/i7pQbiYjHWGorz\njcZWX73tHKMmdal2u4sssl6XWqPK1eo213bjMir1GFFksyWCKIiKTCoxaocl9ml3gYdMKVGrX5lx\nlYZ0aVZswkEtdjvLuBotOuVMOc96QypVGlVhTIkpuy200yJbXWCl9TKGbfz2neaGdZaFu9WHHRrC\nNiF0qQrbXThni5Gh6Xx/tElyxkqXbBaYS68stjdedNiaOa6oX2O4Z631VjnbA7NBP2mfeRp0KZ+9\nJ0DOqPtc4HxrbHCuvdpMyAmmDSvTrMs+84yoMEe3SeUmscEKlQaUGDOu1KRxFQZ1alKvz0ZNlrnf\ngy50gfttsNxc+3SZo0edSv2a9CPa1lGivHJUo/3qddluofn2WGiH+6ySUequjW2WLEtHCklyIqTQ\nPw384tDhR3qXgpVhm2k7dKtFTlRlUtDsoLXOs8R2nZoMK7ZPqwr91lsiZ0SxMcMqREwokTOtTr8J\nZaKsBXZrs89dLnGHq2RNWGK7LMpMWGGTfdq06lRtyLhiWRMGVejXZp4tio0ZV2G5rXaZr1GPIKvV\nbm9Zfqc7XK7YqDqH7NdmStaoCkxZ0jrplw/Uq29KfxiS5HeVQv80tTZe8mvrXrZijfs2BMUGHVSr\nxLBSw/qUz4b9qCadptCj2gEtKgyo1KtPhbMMCYiCgEFVyGjQYUS5MSX2mK9JhyzWuUAwptV+k0ot\nsNugRvW6bXaORh0OmKfeoC6tmhyyzGY/9nTFJrU4ZLNFxtUjWuIhg6rt2V/h4uaHlRtWZsSgStMy\n9mhTYUCpIcWllX74wCKLl6X/xJPkcOn/iDPIN9cf+dxPx/4pV7UdMGrKQbWCjIV2KDJki+Xm6TSk\nQpc6lXpstkC/CvPtsNNcXRoVG1NszJQiWdGkIgTlxlUasd0Cveq02mdakaU2qzLoHhe40p1+4Fme\n7j/d4QpBTpMOHeYYV4th7fY4oF3OuCbdSozrV+siD/iu56k0osaASTm95sqMjnvG8gft1a7aIaPK\nDJijyLAqnbP1TWkoy7l90yRAKkcAABjUSURBVDyt89JRQ3JmSCdyE82tWRviJfbFi+yNq+yJ5/l5\nfK7P/vtyy6y1W5Ny/bZrU2TEiBKjMg6ptsQ203L2abNLu3PdbwrTpgXDxgUjSpQbUW7ItIyMjClZ\ndQ4ZVaFflUW22+4sHdq0zN6spsscM+2SSuNKVOmVETXrcaEHZPBDz1BpzFJbTSlxyFylhsy1T69m\n44qMKzdgnjbbTCg2plKQVSraPVJp6fwDXhr+RU3Y5cpwk+JwQAg9qsJeC8N96sNmbWGLf/3UYH6/\nqCQ5DlLoJ7/RU55XY0O8UoxNdseVeuMi98Vr7IwrXfa8FkOiKh2WucNDLnK+X9rgLBssMW3KHPs0\n6zCJMRkVBuy1QDShS707Xaxatwr9utUrMi5nSpQRBTm/usqnU4sD5llshzFl7nOJ5/iBERWirPXO\nMS3rbA8ZVW29iy2zUYM+feY6172GVGu323z7NerTaY6s6CVucIdrtOq01oXKZ+c0yor61aswrUK/\nN/3pqKLQqSVs1Bw2uTj8REnY75rwXfPCwxrDZiEcsrh2t479U/n74pLkt0jdO8kT8rF/X+Vjv7b2\nOeBNz9jg9h8dNKjOlCITitTr1qNKvV061csYVWxaux3udbEJ1OmyxCY7LJIxplyfPmWgXreh2TMM\nxcZkTSsxrsKoQVVqHHJAq3n2qdFvUL3tlik2CTrM0adFnzoVRowotdg2XRp8yXUu93N3eZKMYArL\nbRJM26Ndjf02Otu0oNUBXRqs8qABVVbZaIezdJuj1V45jPQFZ7ft1qDbAc1q9BtQqdyIKZxrvauu\nKPbfbn/uyfmykuQwqaWfHHef/eHZNsSr7Ymr7I8rdMWz7I3LDcQ2//SPFYZl7deKUfs1qXDIWTa5\n2/lqdQmz8xCVGFamU7lOpYbU67LJYj1qnOMBP3CtQSUaHDCgQrUeEzIeGW6YMfnoUokxBBSrd0iL\nDpNKXOfftNmnXp9aQ8oNqdNjnXM87EIrPSjKikrNdUClESs9bL1VGvU4oM1OK+RMISNr2oRiF3jQ\nbu1KTZpUoty4p/uZSWXI+t4vquVCt9XhFm1hvRD6VIb9cuGAlrBBddjpwiUHDacpkZLjLIV+clJd\n984mfXGJGGvsihfZF8+1MV7ql/Fag3GeG/Y9zaKiQ86y3qCsOgeMytptjmnj5tgnY8J6y4wodr57\nHVTvLBsxNTvwrE3GoAV2GFEEygxiUpFB/ar0qpE1Ya95IKLIuDGlMrIoRkaJSfN0mGuPrIwJJRbb\nodyIIdXKjWm125XusN1yB7UqNWqdVRr0KzGpRYdzPexLXudc6w2rtNZqS213SKP9lisyKWdCKQ5a\nZkCzbdvGzKnYoyLsUxY6VIR95oRNasJOc8JGc8ODMuGA9tLtfnLzRH6+0KTgpO6d5JTS0Fps7fgq\nrDrCozP3B9i/n8sX7zI22mtMsMp9HnauNvt1mjLHTt0a3elJSvUr1mWLFRrtVq/fpGBEhYOa/MjV\netVbZLP9GtXpw4RiA8ZVmBQMKTeqVIUBTAvImjKkUkY0pNx2i5DToN8+C+WMqdEvZ9I2S1zpDiOq\nHDBXpQHP9ANrrbTXIu02KjVqqyWmVGFShQGDak0rMdcOfaoUmTCiXEZWhzZMoMzusWlvePa62aOl\n1QbM12CHHg0udI/t2vWrsLiRNVtbVFWnu+2cyY6ppR9CeHYIYWMIYUsI4T1HePyqEMK9IYTJEMLL\njn+ZSfIrra3sGGl3MK7yy/gcd8bnGIjtNsYnORQX2xYvsHdgnqfM3ylnQItdcjr1aNahxrAiw4pM\nmlZsyEt8zTrLLLTDkCKjiq1yv2Ue9rDzdKnRoVWfaiVGbLXImJxFNpoQlBrVbjemDSkXzXQkZUQj\nSlUZnh24NuaAVlst061x9nxDxm4LbbdEvT5lBjTb5wp3WGk9ivSoN0e3UpMGZiffq9aFMgTtNlps\nh5+51oC5MgbNt0+DbhutkJWRlbO3K6etZo/GsMV54eeKQocQJhSFDueFn2sKm4Rw0Lvf2pe/Lzc5\n4Y7a0g8hZPFxPAN7cHcI4YYY47rDNtuF6/DOE1FkkvyuKiu5ddeKIz3ymKXugw1WLa40PDwhZ9o5\n7veAC6yzVLs9GFZk3NnutdNCh9Taa45mBw0rNaBchyZ3uth8W0zIWWSrTg2gXq9BFUZljCqSManM\nmGhmkBtEOZX6DajRrEvGhChntwXm2aFflW5NBlVot9cui/VrQXCWhzU4aLuzTKnWaqtxZdY516Qy\ni21ySL2g2IQptcbBdksVyVpsrRFldjtLmWHlpn3oE8U+84kdavTbp0W5IUts1a3O8uXlfrDhSJ9r\nUiiOpXvnUmyJMW6DEMJX8UI8Gvoxxh2zj6WZtJKC0jAnZ+9Q22FrVh72+9zHbPvRv93tQ/9jTL8K\n1ehSpckeOaP2aVPvgA7z9arQrEuPWqNq1Ohzhyd5yErX+pF1zlOv0z4tiGodNK5EtR6H1KrTrdiY\nEsOmZUzLGFeszLg2e+22UJw9SC837GIP+E8toEeTZTYZUq5bnS2WI6fOQedZK2PKrZ4qKlVkaDbw\nl83eryEa1qRUjzq9BtRYYbN+FR5yoSLjdm+sdG64007thlWLipGT0WNapfLynG3bsubMOYFfWvJ7\nOZbQn4vdhy3vwZOeyM5CCG/Gm6G9vf2JvESS5M2ff2C+P//AI0utR9jiQjA4EF26ZNxg55CMMf0q\nTYuu8mMPWa5Rh7tcrMVBrTYaUqfUqHHBoFqDqkxjSk6Heap0WGqzHRZ4wPmPBj7kTOhVLTt7aeq0\njHIjxhUbUsOjI6OHPegi7XZqs0+3ORbZpFe9FR6UM+mAZvNslzVtm2UoUmHYoBqVhvRrcIF73OMS\nNXpFFaocMKDFtHptNts3PMfylkMmlIumjZiDMcvcb0r0vNe3+egXFp6oryg5Bif16p0Y46djjKtj\njKubmppO5q6T5KSprArWdSzQHc/WGc/XE5fYHVf6aXyRffEcD8Ynu+nmBsXG1epWoseQYllTyu3H\ntAHlFtqg0n7lBuw0b/YeBvs12qHZDkT3uswvXWS/RlCv015zHFKnVreZk71RlJExMXseISgxpn62\nSymDMWVGVSkxrlGXOkNe6Dsa9OjSpts8GRO61aNEnxZMGZg9wmix0z7zVRlWZ8iwRiNaLPagat2i\nEp0W+OQXa5SFg+rDLiGMC2FaCNNKQqeGsElR6PLDH+bhSzuDHEtLfy/mH7Y8b3ZdkiRP0BXPrPRg\nvPK3bDHX/r2tnrRkt64xRpSrMCAqnp3srlxWjyl1hpW7xi1ud7mD5oq4wC894HyLbdKt0Ygyy60T\nZew3x7RyWyxQ54BxudmLUUdmjyKCSgOyJu03l9lzD2fZboeF5tlhj0Va7HVAO4KsSc06dZgvYxoZ\nZ7tXRlRlSKcm4yoEU+bZZ4sLQDBhofW2W2XKpGlFXvjMA8iaEE2qwTizM6wyImdUmYzb7qlz/kVp\nzqTf1bG09O/G0hDCohBCMV6FG05sWUmStM7N2DW6wHBcKsZ6g3GBnrjYobjISJxjMtaLMdgbl3vy\nP7xWiTHL3Y3ofuc6yyY7tMgY0aPKRkvs06zdVhm9+lWo1Wezc+zWrluNg+Y4qMFuc621Uot9zA5w\n61MtY0qYnR5jeHa0NDNXKlUbMMe+2aMApmWts0qNQb1ajckZU2eL82efFZTrtd0qwZQ+daoMKDYt\nZ1JGqZnxEpVKdKt0SLkRJaYMqPbkiw8oD/uVhENCGBbClBB6Zv/tUpIdtHbtSfu6CsZRQz/GOInr\ncTPW4+sxxodDCO8LIbwAQgiXhBD24OX4VAjh4RNZdJIkj/VXf8XeuML6eKUYS8VYb1NcbSo2ORQX\ni7HSwfGFVl67SLcK8202IlrnLMvcbUxOu22icSNKLLDRkFKDStXZr1SPUcVa7bHbQlDk8AFhweTs\nSedHjgyadSNnWCWy5jlgqfWzjwfBtGZd4Mlu1axDn1Y5UwY0G5/9o1Kj05gGw2qVmDJkjtrZ6bsb\nDBpXp1o/MiqNmom1InOnt7hs1QHVYY8QhrWFjdrCBg1hp9qw3/j4SfhiTkHHNDgrxngTbnrcuvce\n9vvdzA5tTJLklFRUxI0/LMeS2Z9HNM7+OzMg7mPv3evP39+qyX4dajXaY4uzjZqjxCCGFJnSrY3Z\nrpyscXstMKFMlU4Dmu00z8xAt5nzCuOKZ6ermJEz4aA2M508WZ2akdGt1Uxwz/wBGVCp1U5DyvVo\n1GKXKXSar3/2qKPfHFljBrWo1K3dNh1aTStSZky5fiMqtNmrR1aXKnUlBwxrfHQgHlkNDRO6ukpP\n2HdwKkjTMCRJ8hjveN9cMTbpiKv0xCU2xyeJsUaMxT7yleWYVmcXus10/UzaYYUGezXbptohRIOq\nXOxO44JKnYYV227Z7HOiCSWW2GRmpMKEMo9MNPTYK7+nFRlSoX/2LnDdGvVqNBNfOXNmTzFWmhlU\nNqjBOhebFoyqV2FEnUHnWq9XvX51ygwbNgcjxtWq0aFEt+HuXiFMyYVBtWG3pTW7TvTHfdKl0E+S\n5Ji94lUZMdY5GC8QY6MYc2IsEmOwPy7z8w2LHVSHLj1qbLfAtGkt9hhQr8J+7dbPvlq0zQJEd3iK\nCUUy+rXYbeak7RSiGl2KjanWiykVhhT5Vd9M8ezvg6oPqzSjwohme3VocdAct7tCj3pDqvWbq9Ee\nVGqw18wtRXNGNKtywJRyg8rt6K+RC/2PnjOYFzb7+7d2nPgP+gRKoZ8kyXGzdHnGRGwRY7MYK3TH\nhXbGlTbHi8VY7G1/yi5Ngk5MGtKkym7TclrsVmzEAfNk9SnVD/o06zLPgFp1DupXa9qUmctRJ+2Z\n7Vmumz0/8IgpQc6UCqMmlaLUiFpzzIR2l2bMnJsYVm5cnTI9BrQKBpWbUK3XlCpP9yO19ttrif/2\niSYhxNnLTfnWt07Sh3ucpNBPkuSk+eAn28TYbDo2zx4hZPTHBWLM2hXPMRJbfO7jY7LGZPSj30x3\nz7iIYSUyBmVNKNelwQFREQZ0zY6gzhiQ02ta1j7zTYrKZyfSY8qURy7znIm/TnPU6QG1+mWNi6oM\naHRIu4vc4QEX6n308tWZn5xhjPnjl+02J+zUGHaetM/x95FCP0mSU8ob3lJtLLYZigtnzyUUibFE\njCVGY5OJ2GAwtvnQx+YYwcy5hWL0yxg2rcKkUge0KHdQhX6NOl3h5xbZ/OiNeWpnW/y/utcCA2rN\ntQfMNxPivWp0PToCe2a7Ct0yaLFPzpQOrbrVPzrYbP68U3eq6xT6SZIUpLe+PWsozp89t1AqxlpT\nsUKMWTGWmZoq09ac1SunW7mN5hqSm52QukOvVmaPAnpmJ+IrMWhY+eweZgJ+Sg7ZR5dhSJXM7MR5\nw6rMTHdR6ZGjgI69I2pCh/Jw6CR9GscuhX6SJKelTIbNB5sNxSUG4wJdcYWDcbkYa/3Vu0qxD5O6\nzJU1jn7jimdb9dFuMxPxFc1ecvrIIDVmxiA36XLQAkNqH107Y8S4clE0ona29T96st72UaXQT5Lk\njPP3H6oR4zwxFouxyEhsMTZSZci0nANKHRJEQb9xJSoed5J4ZhjaI/37vxqQNtNlVGxmfEGzGl3K\n9KJYCNNKQ+/JfaNHkEI/SZIExaUZU7HVRGw1EhsNj5SJsnZp0GIHh7X4p0x6/HgC6NWkyX5kLLBJ\nnyYj6jzS7TOmRr5noE+hnyRJcgSlpcRYKcZ6W+KlYiz2pc+NmBk/kNWhHmNmwv+Rrp+gc7ZbaKdH\npo+PGu13ePdQbcjftf4p9JMkSY7Ra95QPjsgrdhwbFZiv1KPnKyNj/spRVBqcPY8wSPdQEGfJpev\n7M/Le0ihnyRJ8gSNxkVGYpNLV/ZgSrkOVTr8qo+/06gqh1/588jvdz5UdbLLRQr9JEmS39tdD9aL\nMWcothhQ6ZEBZZUGfsMzZoL/mc88WRX+Sgr9JEmS4yjGajFmles2quS3bpuPu4Sl0E+SJDkBhmKb\nu7a0/ZYtwm957MRJoZ8kSXKCLF4SPPbqnl93sm/mkkI/SZLkBBoaeuwUDo93220nrxZS6Cf/f3vn\nFmJHlYXh77djtyZKLhpijxGTMOIQRTQETVBk8BIviHlR6IwwmYwiRAUvD5IgCPqmyMw4MIyKF0RM\nxjHeYnDIaPRpGKLdmmjHpE1rokaM3V4DgnhbPux1ksqZtH2mzzl19vGsD4ratWrX3j+1d62q2lW1\nKgiCpjJ58s+vnzWrHB0VwukHQRA0meOOO7T9sMPglFPK1RJOPwiCoMns2AHd3QfbJNi0Kc3LpKYf\nowdBEAQTZ+pU2LcP1qyB55+HU0+FlSuht3f8bRtNOP0gCIIS6OmBFSvS1EpieCcIgqCDCKcfBEHQ\nQYTTD4Ig6CDC6QdBEHQQNTl9SRdLGpI0LGnVIdb3SHrC12+WNKfRQoMgCIL6GdfpS+oC/gZcAswH\nlkmaX5XtauALM/s18GfgrkYLDYIgCOqnliv9M4FhM3vPzL4F/gEsrcqzFHjU0+uA86WyPzkIgiAI\nxqMWp3888GFheY/bDpnHzL4HvgKOqS5I0rWS+iX1j46OTkxxEARBMGFKfZBrZg+Y2UIzWzhz5swy\nqw6CIAiozel/BJxQWJ7ttkPmkTQJmAp81giBQRAEQeOoJQzDa8BJkuaSnHsf8LuqPOuB5cB/gSuA\nl81s7L8GAAMDA59Kev//lwzAscCnE9y2DHLWl7M2yFtfztog9NVDztrgYH0n1lPQuE7fzL6XdAOw\nEegCHjazbZLuBPrNbD3wEPCYpGHgc9KJYbxyJzy+I6nfzBZOdPtmk7O+nLVB3vpy1gahrx5y1gaN\n1VdTwDUzewF4ocp2eyH9DXBlIwQFQRAEzSO+yA2CIOgg2tXpP9BqAeOQs76ctUHe+nLWBqGvHnLW\nBg3Up3GetwZBEAS/INr1Sj8IgiCYAOH0gyAIOoi2c/rjRfxsUp0PSxqRNFiwzZD0oqSdPp/udkn6\nq+t7U9KCwjbLPf9OScsbqO8ESa9IelvSNkk35qJR0hGSXpW01bXd4fa5HpF12CO0drt9zIitkla7\nfUjSRfVqK5TbJekNSRsy1LZb0luStkjqd1vL27VQ7jRJ6yTtkLRd0uIc9Ek62fdZZdon6aYctBXK\nvdmPiUFJa/1YaX7fM7O2mUjfCbwLzAO6ga3A/BLqPRdYAAwWbHcDqzy9CrjL05cC/wIELAI2u30G\n8J7Pp3t6eoP09QILPH008A4pImrLNXodR3n6cGCz1/lPoM/t9wErPX0dcJ+n+4AnPD3f27sHmOv9\noKtB++8WYA2wwZdz0rYbOLbK1vJ2LWh5FLjG093AtJz0efldwF7SR01ZaCPFK9sFHFnoc38oo+81\nZKeWNQGLgY2F5dXA6pLqnsPBTn8I6PV0LzDk6fuBZdX5gGXA/QX7QfkarPU54MLcNAKTgdeBs0hf\nF06qblfSR4CLPT3J86m6rYv56tQ0G9gEnAds8Lqy0OZl7eZ/nX4W7UoKt7ILfyEkN32F8pYA/8lJ\nGweCVM7wvrQBuKiMvtduwzu1RPwsi1lm9rGn9wKzPD2WxlK0+23fGaQr6iw0+vDJFmAEeJF0NfKl\npYis1fWMFbG1WfvvL8CtwI++fExG2gAM+LekAUnXui2LdiVdWY4Cj/jw2IOSpmSkr0IfsNbTWWgz\ns4+Ae4APgI9JfWmAEvpeuzn9LLF0im35u6+SjgKeAm4ys33Fda3UaGY/mNnppKvqM4HftEJHNZIu\nA0bMbKDVWn6Gc8xsAeknRtdLOre4ssV9bxJp2PPvZnYG8DVpyGQ/rT42fEz8cuDJ6nWt1ObPEpaS\nTpy/AqYAF5dRd7s5/VoifpbFJ5J6AXw+4vaxNDZVu6TDSQ7/cTN7OkeNZvYl8ArptnWaUkTW6nrG\nitjaDG1nA5dL2k36OdB5wL2ZaAP2XxFiZiPAM6STZi7tugfYY2abfXkd6SSQiz5IJ8vXzewTX85F\n2wXALjMbNbPvgKdJ/bHpfa/dnP7+iJ9+Bu8jRfhsBZXIovj8uYL99/42wCLgK7+d3AgskTTdz/JL\n3FY3kkQKerfdzP6Uk0ZJMyVN8/SRpGcN20nO/4oxtFU0FyO2rgf6/C2GucBJwKv1aDOz1WY228zm\nkPrSy2Z2VQ7aACRNkXR0JU1qj0EyaFcAM9sLfCjpZDedD7ydiz5nGQeGdioactD2AbBI0mQ/fiv7\nrvl9r1EPS8qaSE/Z3yGNC99WUp1rSeNu35Gubq4mjadtAnYCLwEzPK9I/xR+F3gLWFgo54/AsE8r\nGqjvHNJt6pvAFp8uzUEjcBrwhmsbBG53+zzvnMOkW+8etx/hy8O+fl6hrNtc8xBwSYPb+LcceHsn\nC22uY6tP2yr9PYd2LZR7OtDv7fss6Q2XLPSRhkw+A6YWbFlo83LvAHb4cfEY6Q2cpve9CMMQBEHQ\nQbTb8E4QBEFQB+H0gyAIOohw+kEQBB1EOP0gCIIOIpx+EARBBxFOPwiCoIMIpx8EQdBB/ATscTD9\nU7a+mAAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"tnqZf2sCiT6U","colab_type":"code","outputId":"49219fc0-f5f0-489d-bd27-92c7f2b68602","executionInfo":{"status":"ok","timestamp":1578375748435,"user_tz":300,"elapsed":1679,"user":{"displayName":"Marie-Ève Malette","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAwrTYZPeFd3b_Z0e7IC2Dx9pDRjjRt8MpBXw4CRw=s64","userId":"09624672134210041988"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["# avg of top 100 and bottom 100 \n","top100 = data_summary.iloc[:100]\n","print('Avg probability of having 1 accident or more: ', 100*np.round(top100.mean(0)[0],2), '%')\n","print('Avg number of accidents: ', np.round(top100.mean(0)[1],2))\n","print('--------------------------------------------------------')\n","bottom100 = data_summary.iloc[-100:]\n","print('Avg probability of having 1+ accident: ', 100*np.round(bottom100.mean(0)[0],2), '%')\n","print('Avg number of accidents: ', np.round(bottom100.mean(0)[1],2))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Avg probability of having 1 accident or more:  34.0 %\n","Avg number of accidents:  0.34\n","--------------------------------------------------------\n","Avg probability of having 1+ accident:  5.0 %\n","Avg number of accidents:  0.03\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"k-V1PUmuILcz","colab_type":"text"},"source":["### Conclusion:\n"]}]}